{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our tuned sentiment analysis model\n",
    "\n",
    "We start my loading in a dataset of nearly 500 text pieces classified as one of `[negative, positive, neutral]`. \n",
    "\n",
    "We'll also split it into train and test sets so that we can evaluate the performance of our fine-tuned model against the base Gemini model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0              What a great day!!! Looks like dream.  positive\n",
       "1     I feel sorry, I miss you here in the sea beach  positive\n",
       "2                                     Don't angry me  negative\n",
       "3  We attend in the class just for listening teac...  negative\n",
       "4                  Those who want to go, let them go  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sentiment_analysis.csv')\n",
    "\n",
    "# only keep the 'text' and 'sentiment' columns\n",
    "df = df[['text', 'sentiment']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep a consistent random state for reproducibility\n",
    "RANDOM_STATE = 12345\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune a Gemini base model on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available base models: ['tunedModels/classify-sentiment-v1']\n",
      "My tuned models: ['tunedModels/classify-sentiment-v1']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from load_creds import load_creds\n",
    "import google.generativeai as genai\n",
    "\n",
    "creds = load_creds()\n",
    "\n",
    "genai.configure(credentials=creds)\n",
    "\n",
    "print()\n",
    "print('Available base models:', [m.name for m in genai.list_tuned_models()])\n",
    "print('My tuned models:', [m.name for m in genai.list_tuned_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-1.0-pro-001',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
       "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
       "                   'model that supports tuning.'),\n",
       "      input_token_limit=30720,\n",
       "      output_token_limit=2048,\n",
       "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
       "      temperature=0.9,\n",
       "      top_p=1.0,\n",
       "      top_k=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our base model to tune\n",
    "base_model = [\n",
    "    m for m in genai.list_models()\n",
    "    if \"createTunedModel\" in m.supported_generation_methods][0]\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our training data\n",
    "training_data = [\n",
    "    {\"text_input\": text, \"output\": sentiment}\n",
    "    for text, sentiment in zip(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model\n",
    "name = f'classify-sentiment-v1'\n",
    "# operation = genai.create_tuned_model(\n",
    "#     source_model=base_model.name,\n",
    "#     training_data=training_data,\n",
    "#     id = name,\n",
    "#     epoch_count = 100,\n",
    "#     batch_size=4,\n",
    "#     learning_rate=0.001,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<State.ACTIVE: 2>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "\n",
    "model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "model = operation.result()\n",
    "\n",
    "snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
    "\n",
    "sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our new tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our general settings\n",
    "config = {\n",
    "            \"max_output_tokens\": 2048, \n",
    "            \"temperature\": 0, \n",
    "            \"top_p\": 1, \n",
    "            \"top_k\": 32\n",
    "        }\n",
    "\n",
    "# Setup our safety settings\n",
    "safety_config = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the process to test the base model and tuned model\n",
    "test_data = [\n",
    "    {\"text_input\": text, \"output\": sentiment}\n",
    "    for text, sentiment in zip(X_test, y_test)\n",
    "]\n",
    "\n",
    "# This function is used to get a response for our base model\n",
    "def get_sentiment(text, model):\n",
    "    \"\"\"Return the sentiment of the given text as 'positive', 'negative', or 'neutral'.\"\"\"\n",
    "    prompt = \"Classify the sentiment of the following text as 'positive', 'negative', or 'neutral':\\n\\n\" + text\n",
    "    response = model.generate_content(prompt, safety_settings=safety_config)\n",
    "    result = response.text.strip().lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for data in test_data:\n",
    "    text = data['text_input']\n",
    "    sentiment = data['output']\n",
    "    results.append({'text': text, 'actual': sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy of the model on the test data\n",
    "normal_model = genai.GenerativeModel('gemini-pro')\n",
    "tuned_model = genai.GenerativeModel(model_name=\"tunedModels/classify-sentiment-v1\", safety_settings=safety_config)\n",
    "for data in results:\n",
    "    if 'base_predicted' not in data:\n",
    "        data['base_predicted'] = get_sentiment(data['text'], normal_model)\n",
    "    if 'tuned_predicted' not in data:\n",
    "        data['tuned_predicted'] = tuned_model.generate_content(text).text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # predictions: 100\n",
      "Tuned model # predictions: 100\n",
      "Actual # predictions: 100\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percent of test points that have been predicted for each model\n",
    "base_predicted = [data['base_predicted'] for data in results]\n",
    "tuned_predicted = [data['tuned_predicted'] for data in results]\n",
    "actual = [data['actual'] for data in results]\n",
    "\n",
    "print('Base model # predictions:', len(base_predicted))\n",
    "print('Tuned model # predictions:', len(tuned_predicted))\n",
    "print('Actual # predictions:', len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy: 68.00%\n",
      "Tuned model accuracy: 34.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for both models\n",
    "normal_correct = 0\n",
    "tuned_correct = 0\n",
    "for data in results:\n",
    "    if data['actual'] == data['base_predicted']:\n",
    "        normal_correct += 1\n",
    "    if data['actual'] == data['tuned_predicted']:\n",
    "        tuned_correct += 1\n",
    "\n",
    "normal_accuracy = normal_correct / len(results)\n",
    "tuned_accuracy = tuned_correct / len(results)\n",
    "\n",
    "print(f'Base model accuracy: {normal_accuracy:.2%}')\n",
    "print(f'Tuned model accuracy: {tuned_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out our tuned model is not more accurate than the base model. We will stick with the base model for this project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
