{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our tuned sentiment analysis model\n",
    "\n",
    "We start my loading in a dataset of nearly 500 text pieces classified as one of `[negative, positive, neutral]`. \n",
    "\n",
    "We'll also split it into train and test sets so that we can evaluate the performance of our fine-tuned model against the base Gemini model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0              What a great day!!! Looks like dream.  positive\n",
       "1     I feel sorry, I miss you here in the sea beach  positive\n",
       "2                                     Don't angry me  negative\n",
       "3  We attend in the class just for listening teac...  negative\n",
       "4                  Those who want to go, let them go  negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sentiment_analysis.csv')\n",
    "\n",
    "# only keep the 'text' and 'sentiment' columns\n",
    "df = df[['text', 'sentiment']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep a consistent random state for reproducibility\n",
    "RANDOM_STATE = 12345\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune a Gemini base model on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-1.0-pro-001',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
       "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
       "                   'model that supports tuning.'),\n",
       "      input_token_limit=30720,\n",
       "      output_token_limit=2048,\n",
       "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
       "      temperature=0.9,\n",
       "      top_p=1.0,\n",
       "      top_k=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Get our base model to tune\n",
    "base_model = [\n",
    "    m for m in genai.list_models()\n",
    "    if \"createTunedModel\" in m.supported_generation_methods][0]\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our training data\n",
    "training_data = [\n",
    "    {\"text_input\": text, \"output\": sentiment}\n",
    "    for text, sentiment in zip(X_train, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model\n",
    "name = f'classify-sentiment-v1'\n",
    "# operation = genai.create_tuned_model(\n",
    "#     source_model=base_model.name,\n",
    "#     training_data=training_data,\n",
    "#     id = name,\n",
    "#     epoch_count = 100,\n",
    "#     batch_size=4,\n",
    "#     learning_rate=0.001,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<State.CREATING: 1>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "\n",
    "model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8446/9975 [2:27:44<26:44,  1.05s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m operation\u001b[38;5;241m.\u001b[39mwait_bar():\n\u001b[1;32m----> 4\u001b[0m   time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for status in operation.wait_bar():\n",
    "  time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our new tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the process to test the base model and tuned model\n",
    "test_data = [\n",
    "    {\"text_input\": text, \"output\": sentiment}\n",
    "    for text, sentiment in zip(X_test, y_test)\n",
    "]\n",
    "\n",
    "# This function is used to get a response for our base model\n",
    "def get_sentiment(text, model):\n",
    "    \"\"\"Return the sentiment of the given text as 'positive', 'negative', or 'neutral'.\"\"\"\n",
    "    prompt = \"Classify the sentiment of the following text as 'positive', 'negative', or 'neutral':\\n\\n\" + text\n",
    "    response = model.generate_content(prompt)\n",
    "    result = response.text.strip().lower()\n",
    "    return result\n",
    "\n",
    "# Setup our safety settings\n",
    "safety_settings = {\n",
    "    'HARASSMENT': 'MEDIUM',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Setup our safety settings\n",
    "safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        'HARASSMENT': 'block_none',\n",
    "        'HATE_SPEECH': 'block_none',\n",
    "        'INAPPROPRIATE_CONTENT': 'block_none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  i know!!, Sentiment: neutral\n",
      "Predicted: positive, Actual: neutral\n",
      "##############################################\n",
      "Text:  If only we could ever actually be allowed to stay here and do that, Sentiment: neutral\n",
      "Predicted: positive, Actual: neutral\n",
      "##############################################\n",
      "Text:  laughs I`m glad that you have self confidence - it`s a wonderful trait to have  I`ll applaud extra loud for it, okay?, Sentiment: positive\n",
      "Predicted: positive, Actual: positive\n",
      "##############################################\n",
      "Text:  Not going to dwell on it. It happened, it`s passed. Just a shame as he was so supportive! Such is life!  x, Sentiment: negative\n",
      "Predicted: neutral, Actual: negative\n",
      "##############################################\n",
      "Text: I'm depressed, I'm thinking about suicide, what I need to do now?, Sentiment: negative\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m predicted_sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_sentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Actual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##############################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m, in \u001b[0;36mget_sentiment\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassify the sentiment of the following text as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m text\n\u001b[0;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[1;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\evanf\\google-hackathon\\venv\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:331\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].parts[0].text`\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list or parts list does not contain exactly one entry.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m     parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.text` quick accessor only works when the response contains a valid \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Part`, but none was returned. Check the `candidate.safety_ratings` to see if the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\evanf\\google-hackathon\\venv\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:311\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.parts\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    309\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.parts` quick accessor only works for a single candidate, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.parts` quick accessor only works with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle candidate. With multiple candidates use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult.candidates[index].text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked."
     ]
    }
   ],
   "source": [
    "# Get the accuracy of the model on the test data\n",
    "normal_model = genai.GenerativeModel('gemini-pro')\n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "results_base = []\n",
    "for data in test_data:\n",
    "    text = data['text_input']\n",
    "    sentiment = data['output']\n",
    "    print(f\"Text: {text}, Sentiment: {sentiment}\")\n",
    "    predicted_sentiment = get_sentiment(text, normal_model)\n",
    "    print(f\"Predicted: {predicted_sentiment}, Actual: {sentiment}\")\n",
    "    print(\"##############################################\")\n",
    "    results_base.append({'text': text, 'predicted': predicted_sentiment, 'actual': sentiment, 'correct': predicted_sentiment == sentiment})\n",
    "    if predicted_sentiment == sentiment:\n",
    "        correct += 1\n",
    "\n",
    "base_model_accuracy = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy of the tuned model\n",
    "tuned_model = genai.get_tuned_model(f'tunedModels/{name}')\n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "results_tuned = []\n",
    "for data in test_data:\n",
    "    text = data['text_input']\n",
    "    sentiment = data['output']\n",
    "    predicted_sentiment = tuned_model.generate_content(text)\n",
    "    results_tuned.append({'text': text, 'predicted': predicted_sentiment, 'actual': sentiment, 'correct': predicted_sentiment == sentiment})\n",
    "    if predicted_sentiment == sentiment:\n",
    "        correct += 1\n",
    "\n",
    "tuned_model_accuracy = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanf\\google-hackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available base models: []\n",
      "My tuned models: []\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from load_creds import load_creds\n",
    "\n",
    "creds = load_creds()\n",
    "\n",
    "genai.configure(credentials=creds)\n",
    "\n",
    "print()\n",
    "print('Available base models:', [m.name for m in genai.list_tuned_models()])\n",
    "print('My tuned models:', [m.name for m in genai.list_tuned_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-1.0-pro-001',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
       "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
       "                   'model that supports tuning.'),\n",
       "      input_token_limit=30720,\n",
       "      output_token_limit=2048,\n",
       "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
       "      temperature=0.9,\n",
       "      top_p=1.0,\n",
       "      top_k=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = [\n",
    "    m for m in genai.list_models()\n",
    "    if \"createTunedModel\" in m.supported_generation_methods][0]\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content('Classify the following as positive or negative sentiment: thats all the help I needed, thanks')\n",
    "\n",
    "response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
